# Large model configuration
decoder_model_name: HuggingFaceTB/SmolLM2-1.7B-Instruct

# LoRA configuration
use_lora: true
lora_r: 32
lora_alpha: 12
lora_dropout: 0.05
lora_target_modules:
  - q_proj
  - v_proj
  - k_proj
  - o_proj