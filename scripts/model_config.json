{
  "encoder_dim": 512,
  "num_encoder_layers": 12,
  "num_attention_heads": 8,
  "feed_forward_expansion_factor": 4,
  "conv_expansion_factor": 2,
  "input_dropout_p": 0.1,
  "feed_forward_dropout_p": 0.1,
  "attention_dropout_p": 0.1,
  "conv_dropout_p": 0.1,
  "conv_kernel_size": 15,
  "half_step_residual": true,
  "decoder_model_id": "HuggingFaceTB/SmolLM2-1.7B-Instruct",
  "use_lora": true,
  "lora_rank": 32,
  "lora_alpha": 32,
  "lora_dropout": 0.05,
  "lora_target_modules": ["q_proj", "v_proj", "k_proj", "o_proj"],
  "projector_type": "deep",
  "num_projector_layers": 2,
  "projector_dropout": 0.1,
  "num_queries": 128,
  "projector_num_heads": 8
}